{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Copyright 2016 NeuroData (http://neurodata.io)\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "\n",
    "# ndmg_dwi_pipeline.py\n",
    "# Created by Greg Kiar and Will Gray Roncal on 2016-01-27.\n",
    "# Email: gkiar@jhu.edu, wgr@jhu.edu\n",
    "# Edited by Eric Bridgeford on 2017-07-13.\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from datetime import datetime\n",
    "from subprocess import Popen, PIPE\n",
    "from ndmg.stats.qa_regdti import *\n",
    "from ndmg.stats.qa_tensor import *\n",
    "from ndmg.stats.qa_fibers import *\n",
    "from ndmg.stats.qa_mri import qa_mri\n",
    "import ndmg.utils as mgu\n",
    "import ndmg.register as mgr\n",
    "import ndmg.track as mgt\n",
    "import ndmg.graph as mgg\n",
    "import ndmg.preproc as mgp\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import os\n",
    "from ndmg.graph import biggraph as ndbg\n",
    "import traceback\n",
    "from ndmg.utils.bids_utils import name_resource\n",
    "import sys\n",
    "\n",
    "\n",
    "os.environ[\"MPLCONFIGDIR\"] = \"/tmp/\"\n",
    "\n",
    "\n",
    "def ndmg_dwi_worker(dwi, bvals, bvecs, t1w, atlas, mask, labels, outdir,\n",
    "                    clean=False, big=False):\n",
    "    \"\"\"\n",
    "    Creates a brain graph from MRI data\n",
    "    \"\"\"\n",
    "    startTime = datetime.now()\n",
    "    fmt = '_elist.ssv'\n",
    "    # Create derivative output directories\n",
    "    namer = name_resource(dwi, t1w, atlas, outdir)\n",
    "\n",
    "    paths = {'prep_m': \"dwi/preproc\",\n",
    "             'prep_a': \"anat/preproc\",\n",
    "             'reg_m': \"dwi/registered\",\n",
    "             'reg_a': \"anat/registered\",\n",
    "             'tensor': \"dwi/tensor\",\n",
    "             'fiber': \"dwi/fiber\",\n",
    "             'voxelg': \"dwi/voxel-connectomes\",\n",
    "             'conn': \"dwi/roi-connectomes\"}\n",
    "\n",
    "    opt_dirs = ['prep_m', 'prep_a', 'reg_m', 'reg_a']\n",
    "    clean_dirs = ['tensor', 'fiber']\n",
    "    label_dirs = ['conn']  # create label level granularity\n",
    "\n",
    "    namer.add_dirs(paths, labels, label_dirs)\n",
    "    qc_stats = \"{}/{}_stats.csv\".format(namer.dirs['qa']['base'],\n",
    "        namer.get_mod_source())\n",
    "\n",
    "    # Create derivative output file names\n",
    "    reg_dname = \"{}_{}\".format(namer.get_mod_source(),\n",
    "        namer.get_template_info())\n",
    "    reg_aname = \"{}_{}\".format(namer.get_anat_source(),\n",
    "        namer.get_template_info())\n",
    "    \n",
    "    preproc_dwi = namer.name_derivative(namer.dirs['output']['prep_m'],\n",
    "        \"{}_preproc.nii.gz\".format(namer.get_mod_source()))\n",
    "    motion_dwi = namer.name_derivative(namer.dirs['tmp']['prep_m'],\n",
    "        \"{}_variant-mc_preproc.nii.gz\".format(namer.get_mod_source()))\n",
    "    preproc_t1w_brain = namer.name_derivative(namer.dirs['output']['prep_a'],\n",
    "        \"{}_preproc_brain.nii.gz\".format(namer.get_anat_source()))\n",
    "\n",
    "    aligned_dwi = namer.name_derivative(namer.dirs['output']['reg_m'],\n",
    "        \"{}_registered.nii.gz\".format(reg_dname))\n",
    "    aligned_t1w = namer.name_derivative(namer.dirs['output']['reg_a'],\n",
    "        \"{}_registered.nii.gz\".format(reg_aname))\n",
    "\n",
    "    tensors = namer.name_derivative(namer.dirs['output']['tensor'],\n",
    "        \"{}_tensor.npz\".format(reg_dname))\n",
    "    fibers = namer.name_derivative(namer.dirs['output']['fiber'],\n",
    "        \"{}_fibers.npz\".format(reg_dname))\n",
    "\n",
    "    print(\"This pipeline will produce the following derivatives...\")\n",
    "    if not clean:\n",
    "        print(\"dMRI volumes preprocessed: {}\".format(preproc_dwi))\n",
    "        print(\"T1w volume preprocessed: {}\".format(preproc_t1w_brain))\n",
    "        print(\"dMRI volume registered to template: {}\".format(aligned_dwi))\n",
    "    print(\"dMRI Tensors: {}\".format(tensors))\n",
    "    print(\"dMRI Fibers: {}\".format(fibers))\n",
    "\n",
    "    if big:\n",
    "        voxel = namer.name_derivative(namer.dirs['output']['voxel'],\n",
    "            \"{}_voxel-connectome.npz\".format(reg_dname))\n",
    "        print(\"Voxelwise Fiber Graph: {}\".format(voxel))\n",
    "\n",
    "    # Again, connectomes are different\n",
    "    if not isinstance(labels, list):\n",
    "        labels = [labels]\n",
    "    connectomes = [namer.name_derivative(\n",
    "        namer.dirs['output']['conn'][namer.get_label(lab)],\n",
    "        \"{}_{}_measure-spatial-ds{}\".format(namer.get_mod_source(),\n",
    "            namer.get_label(lab), fmt)) for lab in labels]\n",
    "\n",
    "    print(\"Connectomes downsampled to given labels: \" +\n",
    "          \", \".join(connectomes))\n",
    "\n",
    "    qc_dwi = qa_mri(namer, 'dwi')  # for quality control\n",
    "    # Align fMRI volumes to Atlas\n",
    "\n",
    "    # -------- Preprocessing Steps --------------------------------- #\n",
    "    # Creates gradient table from bvalues and bvectors\n",
    "    print(\"Generating gradient table...\")\n",
    "    dwi1 = namer.name_derivative(namer.dirs['tmp']['prep_m'],\n",
    "        \"{}_t1.nii.gz\".format(namer.get_mod_source()))\n",
    "    bvecs1 = namer.name_derivative(namer.dirs['tmp']['prep_m'],\n",
    "        \"{}_1.bvec\".format(namer.get_mod_source()))\n",
    "    mgp.rescale_bvec(bvecs, bvecs1)\n",
    "    gtab = mgu.load_bval_bvec_dwi(bvals, bvecs1, dwi, dwi1)\n",
    "\n",
    "    # -------- Registration Steps ----------------------------------- #\n",
    "    # Align DTI volumes to Atlas\n",
    "    print(\"Aligning volumes...\")\n",
    "    mgr().dwi2atlas(dwi1, gtab, t1w, atlas, aligned_dwi, outdir, clean)\n",
    "    b0loc = np.where(gtab.b0s_mask)[0][0]\n",
    "    reg_dti_pngs(aligned_dwi, b0loc, atlas, namer.dirs['qa']['reg_m'])\n",
    "\n",
    "    # -------- Tensor Fitting and Fiber Tractography ---------------- #\n",
    "    # Compute tensors and track fiber streamlines\n",
    "    print(\"Beginning tractography...\")\n",
    "    tens, tracks = mgt().eudx_basic(aligned_dwi, mask, gtab, stop_val=0.2)\n",
    "    tensor2fa(tens, tensors, aligned_dwi, namer.dirs['output']['tensor'],\n",
    "              namer.dirs['qa']['tensor'])\n",
    "\n",
    "    # As we've only tested VTK plotting on MNI152 aligned data...\n",
    "    if nb.load(mask).get_data().shape == (182, 218, 182):\n",
    "        try:\n",
    "            visualize_fibs(tracks, fibers, mask, namer.dirs['qa']['fiber'], 0.02)\n",
    "        except:\n",
    "            print(\"Fiber QA failed - VTK for Python not configured properly.\")\n",
    "\n",
    "    # And save them to disk\n",
    "    np.savez(tensors, tens)\n",
    "    np.savez(fibers, tracks)\n",
    "\n",
    "    # -------- Big Graph Generation --------------------------------- #\n",
    "    # Generate big graphs from streamlines\n",
    "    if big:\n",
    "        print(\"Making Voxelwise Graph...\")\n",
    "        bg1 = ndbg()\n",
    "        bg1.make_graph(tracks)\n",
    "        bg1.save_graph(voxel)\n",
    "\n",
    "    # ------- Connectome Estimation --------------------------------- #\n",
    "    # Generate graphs from streamlines for each parcellation\n",
    "    for idx, label in enumerate(labels):\n",
    "        print(\"Generating graph for {} parcellation...\".format(label))\n",
    "\n",
    "        labels_im = nb.load(labels[idx])\n",
    "        g1 = mgg(len(np.unique(labels_im.get_data()))-1, labels[idx])\n",
    "        g1.make_graph(tracks)\n",
    "        g1.summary()\n",
    "        g1.save_graph(connectomes[idx])\n",
    "\n",
    "    exe_time = datetime.now() - startTime\n",
    "    qc_dwi.save(qc_stats, exe_time)\n",
    "\n",
    "    # Clean temp files\n",
    "    if clean:\n",
    "        print(\"Cleaning up intermediate files... \")\n",
    "        del_dirs = [namer.dirs['tmp']['base']] + \\\n",
    "            [namer.dirs['output'][k] for k in opt_dirs]\n",
    "        cmd = \"rm -rf {}\".format(\" \".format(del_dirs))\n",
    "        mgu.execute_cmd(cmd)\n",
    "\n",
    "    print(\"Execution took: {}\".format(exe_time))\n",
    "    print(\"Complete!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "def ndmg_dwi_pipeline(dwi, bvals, bvecs, t1w, atlas, mask, labels, outdir,\n",
    "                      clean=False, big=False):\n",
    "    \"\"\"\n",
    "    A wrapper for the worker to make our pipeline more robust to errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ndmg_dwi_worker(dwi, bvals, bvecs, t1w, atlas, mask, labels, outdir,\n",
    "                        clean, big)\n",
    "    except Exception, e:\n",
    "        print(traceback.format_exc())\n",
    "        os.exit()\n",
    "    finally:\n",
    "        try:\n",
    "            os.exit()\n",
    "        except Exception, e:\n",
    "            os.exit()\n",
    "    return\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = ArgumentParser(description=\"This is an end-to-end connectome \\\n",
    "                            estimation pipeline from sMRI and DTI images\")\n",
    "    parser.add_argument(\"dwi\", action=\"store\", help=\"Nifti DTI image stack\")\n",
    "    parser.add_argument(\"bval\", action=\"store\", help=\"DTI scanner b-values\")\n",
    "    parser.add_argument(\"bvec\", action=\"store\", help=\"DTI scanner b-vectors\")\n",
    "    parser.add_argument(\"t1w\", action=\"store\", help=\"Nifti T1w MRI image\")\n",
    "    parser.add_argument(\"atlas\", action=\"store\", help=\"Nifti T1 MRI atlas\")\n",
    "    parser.add_argument(\"mask\", action=\"store\", help=\"Nifti binary mask of \\\n",
    "                        brain space in the atlas\")\n",
    "    parser.add_argument(\"outdir\", action=\"store\", help=\"Path to which \\\n",
    "                        derivatives will be stored\")\n",
    "    parser.add_argument(\"labels\", action=\"store\", nargs=\"*\", help=\"Nifti \\\n",
    "                        labels of regions of interest in atlas space\")\n",
    "    parser.add_argument(\"-c\", \"--clean\", action=\"store_true\", default=False,\n",
    "                        help=\"Whether or not to delete intemediates\")\n",
    "    parser.add_argument(\"-b\", \"--big\", action=\"store_true\", default=False,\n",
    "                        help=\"whether or not to produce voxelwise big graph\")\n",
    "    result = parser.parse_args()\n",
    "\n",
    "    # Create output directory\n",
    "    print(\"Creating output directory: {}\".format(result.outdir))\n",
    "    print(\"Creating output temp directory: {}/tmp\".format(result.outdir))\n",
    "    mgu.execute_cmd(\"mkdir -p {} {}/tmp\".format(result.outdir, result.outdir))\n",
    "\n",
    "    ndmg_dwi_pipeline(result.dwi, result.bval, result.bvec, result.t1w,\n",
    "                      result.atlas, result.mask, result.labels, result.outdir,\n",
    "                      result.clean, result.big)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
